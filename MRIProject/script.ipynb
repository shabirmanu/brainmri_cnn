{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2b74a927-46a8-4c75-9aba-11287bed56b8",
    "_uuid": "bd06de28c66d319f23fcd76b331f30c1ef2869e6"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Activation\n",
    "base_path = os.path.join('..', 'input')\n",
    "train_h5_path = os.path.join(base_path, 'food_c101_n10099_r32x32x1.h5')\n",
    "test_h5_path = os.path.join(base_path, 'food_test_c101_n1000_r32x32x1.h5')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64b3ad08-3b26-4e9b-8bc4-df39f85d744c",
    "_uuid": "d855f62d485261518e76c36497f22b06eed3f57d"
   },
   "source": [
    "# Load the training and validation data\n",
    "We use the HDF5Matrix class to make loading the data easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b14e2f51-2a11-4977-b85c-7d9b81f990a9",
    "_uuid": "b4302a8d9eeaa8185aefe48715dff25b282e9db8"
   },
   "outputs": [],
   "source": [
    "X_train = HDF5Matrix(train_h5_path, 'images')\n",
    "y_train = HDF5Matrix(train_h5_path, 'category')\n",
    "print('In Data',X_train.shape,'=>', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14b03b92-e658-4012-a6ef-12e28b26bd2b",
    "_uuid": "452d61f62ee5f040efddad647fe2feb90e97666f"
   },
   "outputs": [],
   "source": [
    "X_test = HDF5Matrix(test_h5_path, 'images')\n",
    "y_test = HDF5Matrix(test_h5_path, 'category')\n",
    "print('In Data',X_test.shape,'=>', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1d00afc603b29fb96d614588c4d692abbf31689"
   },
   "outputs": [],
   "source": [
    "sample_imgs = 25\n",
    "with h5py.File(train_h5_path, 'r') as n_file:\n",
    "    total_imgs = n_file['images'].shape[0]\n",
    "    read_idxs = slice(0,sample_imgs)\n",
    "    im_data = n_file['images'][read_idxs]\n",
    "    im_label = n_file['category'].value[read_idxs]\n",
    "    label_names = [x.decode() for x in n_file['category_names'].value]\n",
    "fig, m_ax = plt.subplots(5, 5, figsize = (12, 12))\n",
    "for c_ax, c_label, c_img in zip(m_ax.flatten(), im_label, im_data):\n",
    "    c_ax.imshow(c_img if c_img.shape[2]==3 else c_img[:,:,0], cmap = 'gray')\n",
    "    c_ax.axis('off')\n",
    "    c_ax.set_title(label_names[np.argmax(c_label)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a23c28f0c3f82ac65d3e9a2828ffcc9c17c511d4"
   },
   "source": [
    "# Building the network\n",
    "We build a very basic neural network for classifying the images, based on a simple Keras demo script. The network is quick to train and well suited for small datasets like the one we are using. Dropout layers have been added to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "862fbcf5-8a19-40b2-b57b-bc254b55d6f3",
    "_uuid": "3448ece339e64b057d645f21075a87551bf05872"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_test.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "loss_history = []\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "81bbd2c3-f7fe-4a2f-99df-90cf6492cb85",
    "_uuid": "b5ca068165dffdcf18a41d3c501e2a05426c47e7"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    loss_history += [model.fit(X_train, y_train,\n",
    "                               validation_data=(X_test, y_test), \n",
    "                               batch_size = 256,\n",
    "                               epochs = 1, shuffle=\"batch\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89e8c15d754e3f3c7e7313b114f7b42f15ee4d40"
   },
   "source": [
    "# Examining Loss\n",
    "The following function shows the loss and accuracy over the course of training. We see the training data curves in blue and the validation in red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e1e564a-a145-4969-b7c8-c9926104d78e",
    "_uuid": "5992a55d8eb69109396e8bd1183b97e86c1a40e8"
   },
   "outputs": [],
   "source": [
    "epich = np.cumsum(np.concatenate(\n",
    "    [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "_ = ax1.plot(epich,\n",
    "             np.concatenate([mh.history['loss'] for mh in loss_history]),\n",
    "             'b-',\n",
    "             epich, np.concatenate(\n",
    "        [mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "ax1.legend(['Training', 'Validation'])\n",
    "ax1.set_title('Loss')\n",
    "\n",
    "_ = ax2.plot(epich, np.concatenate(\n",
    "    [mh.history['acc'] for mh in loss_history]), 'b-',\n",
    "                 epich, np.concatenate(\n",
    "        [mh.history['val_acc'] for mh in loss_history]),\n",
    "                 'r-')\n",
    "ax2.legend(['Training', 'Validation'])\n",
    "ax2.set_title('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0acdf7ba8126cb1d54c4c70029c50100069b364c"
   },
   "source": [
    "# Visualizing Results\n",
    "Here we show the results a small sample of validation images to see how well the predictions match the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c449e416-2df3-4460-8e8a-aff65d0839f5",
    "_uuid": "58bdcedc32efb3a249b71e54047688229c9eed17"
   },
   "outputs": [],
   "source": [
    "sample_imgs = 16\n",
    "with h5py.File(test_h5_path, 'r') as n_file:\n",
    "    total_imgs = n_file['images'].shape[0]\n",
    "    read_idxs = slice(0,sample_imgs)\n",
    "    im_data = n_file['images'][read_idxs]\n",
    "    im_label = n_file['category'].value[read_idxs]\n",
    "    label_names = [x.decode() for x in n_file['category_names'].value]\n",
    "pred_label = model.predict(im_data)\n",
    "fig, m_ax = plt.subplots(4, 4, figsize = (20, 20))\n",
    "for c_ax, c_label, c_pred, c_img in zip(m_ax.flatten(), im_label, pred_label, im_data):\n",
    "    c_ax.imshow(c_img if c_img.shape[2]==3 else c_img[:,:,0], cmap = 'gray')\n",
    "    c_ax.axis('off')\n",
    "    c_ax.set_title('Predicted:{}\\nActual:{}'.format(label_names[np.argmax(c_pred)],\n",
    "                                                  label_names[np.argmax(c_label)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "32f6617b2218605eacff7b3757d8a6840782dcbb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-80784060c951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
